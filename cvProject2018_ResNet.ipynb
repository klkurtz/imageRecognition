{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cvProject2018-ResNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "hoAgYgKM_Fch",
        "IgBojGjbCyPV",
        "QI17JtPSr9dN",
        "RiwjfkwCscHP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hoAgYgKM_Fch",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Image recognition (with ResNets)\n",
        "\n",
        "The goal is to train a neural network for visual recognition (i.e., given an image, predict its class label). Residual networks (ResNets), i.e., are current state-of-the-art architecture for this type of problem.\n",
        "\n",
        "**Resources** (data available via PyTorch)\n",
        "1. CIFAR-10"
      ]
    },
    {
      "metadata": {
        "id": "2RXEF0MmbNgN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First we set up our google colab environment."
      ]
    },
    {
      "metadata": {
        "id": "FCabnfz9pwF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt update -qq;\n",
        "!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n",
        "!dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n",
        "!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub;\n",
        "!apt-get update -qq;\n",
        "!apt-get install cuda gcc-5 g++-5 -y -qq;\n",
        "!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n",
        "!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n",
        "!apt install cuda-8.0;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZbqlCaELu9_-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZouuwIrcrmcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AARrniZBI4A0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Just a little test:"
      ]
    },
    {
      "metadata": {
        "id": "MDdCAIsgAnq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVChd4ZT5yJe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we import torch."
      ]
    },
    {
      "metadata": {
        "id": "JbtXhXHrvPPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgBojGjbCyPV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CIFAR10"
      ]
    },
    {
      "metadata": {
        "id": "fm3Q2yA5CKdc",
        "colab_type": "code",
        "outputId": "1b114c41-56f0-4b8f-a048-c532f4fc27d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Data\n",
        "\n",
        "print('==> Preparing data...')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2) # batch size 128\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2) # batch_size 100\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F-Id4pzuxyyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# CIFAR10\n",
        "train_data = trainloader\n",
        "test_data = testloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QI17JtPSr9dN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#ResNet implemenation\n",
        "We are now able to implement our first ResNet-Model. We use the sample code provided within the PyTorch documentary to explore and tweak the model.\n",
        "\n",
        "First we define the 3x3/1x1 convolution we will later use in our BasicBlock. Note that the stride is set to one as is the padding in the 3x3 convolution. This should keep the dimension of our plane constant."
      ]
    },
    {
      "metadata": {
        "id": "DdK5y8NpsAlF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes,\n",
        "                     out_planes,\n",
        "                     kernel_size=3,\n",
        "                     stride=stride,\n",
        "                     padding=1,\n",
        "                     bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes,\n",
        "                     out_planes,\n",
        "                     kernel_size = 1,\n",
        "                     stride = stride,\n",
        "                     bias=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JpNdwY686oVO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can build the BasicBlock as described in the ResNet paper."
      ]
    },
    {
      "metadata": {
        "id": "WtX2VkvFsEHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x # save x\n",
        "        \n",
        "        # conv -> bn -> relu\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        \n",
        "        # x + F(x) - this realizes the shortcut conn.\n",
        "        out += residual\n",
        "        out = self.relu(out) # final relu\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rEMj9Tlg62Cw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we would like to build a deeper Model as described by He et al. (2015) ResNet-50/101/152\n",
        " we will also need a Bottleneck."
      ]
    },
    {
      "metadata": {
        "id": "qgDPDvvwsMTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    The expansion factor controls the number of output\n",
        "    channels of the last 1x1 convolution layer.\n",
        "    \"\"\"\n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, inplanes, planes, stride = 1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv1x1(inplanes, planes)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
        "        self.bn3 = nn.BatchNorm2d(planes*self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "    \n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "            \n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYmCXuVe7iiE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now specify the ResNet Model. We are also able to change some parameters such as kernel_size, stride, padding or output channels to improve the model."
      ]
    },
    {
      "metadata": {
        "id": "x6ImPIqysQ5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from torchvision.models import resnet18\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1,\n",
        "                               bias=False) \n",
        "        self.bn1 = nn.BatchNorm2d(64) \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) \n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2) \n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)  \n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)  \n",
        "        self.avgpool = nn.AvgPool2d(4, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)      \n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_mOQDcp74VL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With the generic model specified above we can now build a ResNet-18 (18 Layers deep)."
      ]
    },
    {
      "metadata": {
        "id": "_t5dMBKwsYc3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kwargs = {}\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RiwjfkwCscHP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Run the ResNet Model\n",
        "We will now train our Model using the CrossEntropyLoss-Function as this is a classic classification problem where CrossEntropy usually performs well.\n",
        "Note that we evaluate the model after each epoch to find the number of epochs which will minimize our test error and to observe overfitting."
      ]
    },
    {
      "metadata": {
        "id": "1SjGS6kWtncz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "    for x,y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        outputs = model(x)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_corrects += torch.sum(preds == y.data)\n",
        "      \n",
        "    print(\"Accuracy: \", float(running_corrects)/(len(test_data)*64)*100.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lq7l_VOrEUDn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Considering the benchmark table from https://benchmarks.ai/cifar-10 Yamada et al. 2018 report a Top-1 error for the CIFAR10 dataset of 4.08 for 1800 epochs. \n",
        "We take this as our benchmark we would like to come as close as possible with our simple model.\n",
        "Now, finding the best hyperparameters is the tricky part..."
      ]
    },
    {
      "metadata": {
        "id": "52TUdvtJsdPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = 'cuda:0'\n",
        "\n",
        "model = resnet18()\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.5, momentum=0.9)\n",
        "#opt = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08,\n",
        "#                       weight_decay=5e-4, amsgrad=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "n_epochs = 30\n",
        "losses = []\n",
        "#accuracyList = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    e_loss = 0\n",
        "    \n",
        "    for x,y in train_data:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        model.zero_grad()    # zero gradients\n",
        "        out = model(x)       # forward pass\n",
        "        loss = criterion(out, y)  # compute loss\n",
        "        e_loss += loss.item()     # track loss (optional)\n",
        "        loss.backward()           # compute gradients via backprop.\n",
        "        opt.step()                # take an optimizer step\n",
        "        \n",
        "    if i % 1 == 0:\n",
        "      losses.append(e_loss)\n",
        "\n",
        "    print('Epoch {}: {:.4f}'.format(i, e_loss))\n",
        "    evaluate(model, test_data)\n",
        "    #print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}